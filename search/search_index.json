{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Observability","text":"<p>The scope of this project is to evaluate an open sourch tech stack to observe applications regarding logs, metrics and traces. To achieve a real world scenario, a spring boot backend with an nextJS frontend is used as a demo application.</p> <p>The following tools are used:</p> <ul> <li>Prometheus</li> <li>Grafana</li> <li>Promtail</li> <li>Loki</li> <li>Tempo</li> </ul>"},{"location":"getting_started/docu_setup/","title":"Mkdocs Documentation","text":"<p>https://squidfunk.github.io/mkdocs-material/</p> <p>\"Material for MkDocs is a powerful documentation framework on top of MkDocs, a static site generator for project documentation.1 If you're familiar with Python, you can install Material for MkDocs with pip, the Python package manager. If not, we recommend using docker.\" (Martin Donath, 2023)</p>"},{"location":"getting_started/docu_setup/#startup-with-docker-compose","title":"Startup with docker-compose","text":"<p>When the docker-compose startup is used, the documentation is directly available at http://localhost:8000.</p>"},{"location":"getting_started/docu_setup/#local-startup-with-docker","title":"Local startup with Docker","text":"<p>Source: https://squidfunk.github.io/mkdocs-material/getting-started/</p>"},{"location":"getting_started/docu_setup/#pull-image","title":"Pull Image","text":"<p><code>docker pull squidfunk/mkdocs-material</code></p>"},{"location":"getting_started/docu_setup/#start-mkdocs-material","title":"Start Mkdocs material","text":"Unix, PowershellWindows <pre><code>docker run --rm -it -p 8000:8000 -v ${PWD}:/docs squidfunk/mkdocs-material\n</code></pre> <pre><code>docker run --rm -it -p 8000:8000 -v \"%cd%\":/docs squidfunk/mkdocs-material\n</code></pre> <p>Point your browser to localhost:8000</p>"},{"location":"getting_started/endpoints/","title":"Relevant Endpoints","text":""},{"location":"getting_started/endpoints/#application","title":"Application","text":""},{"location":"getting_started/endpoints/#observability-backend","title":"Observability Backend","text":"<p><code>http://localhost:8080/users</code></p>"},{"location":"getting_started/endpoints/#observability-frontend","title":"Observability Frontend","text":"<p><code>http://localhost:4000/</code></p>"},{"location":"getting_started/endpoints/#monitoring","title":"Monitoring","text":""},{"location":"getting_started/endpoints/#grafana-ui","title":"Grafana UI","text":"<p><code>http://localhost:3000/</code></p>"},{"location":"getting_started/endpoints/#prometheus-ui","title":"Prometheus UI","text":"<p><code>http://localhost:9090/</code></p>"},{"location":"getting_started/endpoints/#documentation","title":"Documentation","text":"<p><code>http://localhost:8000/</code></p>"},{"location":"getting_started/project_docker_setup/","title":"Docker Setup Observability Stack","text":""},{"location":"getting_started/project_docker_setup/#preparation","title":"Preparation","text":""},{"location":"getting_started/project_docker_setup/#build-obs-backend","title":"Build OBS backend","text":""},{"location":"getting_started/project_docker_setup/#install-dependencies-and-build-jar","title":"Install Dependencies and build JAR","text":"<p><code>cd ../observability &amp;&amp; ./mvnw package &amp;&amp; cd ../docker-setup</code></p>"},{"location":"getting_started/project_docker_setup/#build-docker-image","title":"Build Docker Image","text":"<p><code>docker build -t tribe.ccc.tt/observability ../observability</code></p>"},{"location":"getting_started/project_docker_setup/#build-nextjs-frontend","title":"Build nextJS frontend","text":""},{"location":"getting_started/project_docker_setup/#install-node_modules","title":"Install node_modules","text":"<p><code>cd ../frontend &amp;&amp; npm install &amp;&amp; cd ../docker-setup</code></p>"},{"location":"getting_started/project_docker_setup/#build-frontend-docker-image","title":"Build Frontend Docker Image","text":"<p><code>docker build -t tribe.ccc.tt/nextjs ../frontend</code></p>"},{"location":"getting_started/project_docker_setup/#build-test-env","title":"Build test env","text":"<p><code>docker-compose up</code> or detached mode (container in background): <code>docker-compose up -d</code></p>"},{"location":"getting_started/project_docker_setup/#stop-test-env","title":"Stop test env","text":"<p><code>docker container stop $(docker container ls -q --filter name=docker-setup*)</code></p>"},{"location":"getting_started/project_docker_setup/#start-test-env","title":"Start test env","text":"<p><code>docker container start $(docker container ls -a -q --filter name=docker-setup*)</code></p>"},{"location":"getting_started/project_docker_setup/#clean-test-env","title":"Clean test env","text":"<p><code>docker-compose down</code></p>"},{"location":"logging/cef/","title":"CEF - Common Event Format","text":""},{"location":"logging/cef/#format-description","title":"Format description","text":"<p>2023-08-17 17:22.048 CEF:1|observability|observability test backend|0.0.1-SNAPSHOT|1305|{username=matze} - JWT Token is generated.|3</p> DATE CEF:Version Device Vendor Device Product Device Version Device Event Class ID Name Severity [Extension] Date CEF:1 Customer name Project name 1.0.1 3001 Login Failed 3 usr=2571f48d-a302-46b0-8295-97b8b1f27a84 Field Description Device Vendor Application / Customer name Device Product Project name Device Version Application Version Device Event Class ID unique identifier for each event-type Name human-readable and understandable description of the event Severity reflects the importance of the event [Extension] contains a collection of key-value pairs"},{"location":"logging/cef/#severity-and-event-class-id-mapping","title":"Severity and Event Class ID mapping","text":"<ul> <li>first digit: severity class</li> <li>second digit: exact severity</li> <li>rest: identifier</li> </ul> <pre><code>CRITICAL 9-10   \n     9901 Access to a backend endpoint was blocked due to missing authentication\n     9902 Access to a backend endpoint was blocked due to missing authorization\n\nHIGH    7- 8\n     7701 Failed account log on\n     7702 A user account was assigned to an admin role\n     7803 A group was assigned to an admin role\n     7804 BadCredentialException\n\n\nMEDIUM  4-6\n     4501 A user account was created\n     4502 A user account was deleted\n     4503 A user account was assigned to a non-admin role\n     4604 A group was created\n     4605 A group was deleted\n     4606 A group was assigned to a non-admin role\n     4607 A configuration/ setting of the application value was changed\n     4608 Repository exception\n\nLOW     0-3\n     1201 Successful account log on\n     1202 An account logged off\n     1303 A user account attribute was changed\n     1304 A group attribute was changed\n     1305 Token generated\n</code></pre> <p>This is an extension of the Application Services EMEA Engineering Practices .</p>"},{"location":"logging/log4j2/","title":"Apache Log4j2 - Backend Logging","text":""},{"location":"logging/log4j2/#advantages-over-log4j-slf4j-and-logback","title":"Advantages over Log4j, Slf4j and Logback","text":"<p>https://logging.apache.org/log4j/log4j-2.2/manual/index.html</p> <ul> <li>Performance -&gt; next-generation lock-free Asynchronous Loggers</li> <li>Customizable configuration with new Appenders, Filters, Layouts, Lookups, and Pattern   Converters</li> <li>Automatically reload its configuration</li> <li>Supported APIs: SLF4J, Commons Logging, Log4j-1.x and java.util.logging</li> <li>Support for Message objects</li> <li>Support Filters that can be configured to process events before they are handled by a Logger</li> </ul>"},{"location":"logging/log4j2/#configuration","title":"Configuration","text":"<p>Source: /tigerteam-observability/observability/src/main/resources/log4j2.xml</p> <pre><code>&lt;Configuration status=\"WARN\" monitorInterval=\"30\"&gt;\n  &lt;Properties&gt;\n    &lt;Property name=\"LOG_PATTERN\"&gt;\n      %d{yyyy-MM-dd HH:mm:ss.SSS} %5p ${hostName} --- [%15.15t] %-40.40c{1.} %-4.4L : %X - %m%n%ex\n    &lt;/Property&gt;\n    &lt;Property name=\"CEF_PATTERN\"&gt;\n      %m%n\n    &lt;/Property&gt;\n    &lt;Property name=\"LOG_DIR\"&gt;/logs&lt;/Property&gt;\n  &lt;/Properties&gt;\n  &lt;Appenders&gt;\n    &lt;RollingRandomAccessFile\n      name=\"RollingCEFFile\"\n      fileName=\"logs/cef.log\"\n      filePattern=\"logs/$${date:yyyy-MM}/cef-%d{MM-dd-yyyy}-%i.log.gz\"&gt;\n      &lt;PatternLayout pattern=\"${CEF_PATTERN}\"/&gt;\n      &lt;Policies&gt;\n        &lt;TimeBasedTriggeringPolicy/&gt;\n        &lt;SizeBasedTriggeringPolicy size=\"10 MB\"/&gt;\n      &lt;/Policies&gt;\n      &lt;DefaultRolloverStrategy max=\"20\"/&gt;\n    &lt;/RollingRandomAccessFile&gt;\n    &lt;RollingRandomAccessFile\n      name=\"RollingDevelopmentFile\"\n      fileName=\"logs/develop/dev.log\"\n      filePattern=\"logs/develop/$${date:yyyy-MM}/dev-%d{MM-dd-yyyy}-%i.log.gz\"&gt;\n      &lt;PatternLayout pattern=\"${LOG_PATTERN}\"/&gt;\n      &lt;Policies&gt;\n        &lt;TimeBasedTriggeringPolicy/&gt;\n        &lt;SizeBasedTriggeringPolicy size=\"10 MB\"/&gt;\n      &lt;/Policies&gt;\n      &lt;DefaultRolloverStrategy max=\"20\"/&gt;\n    &lt;/RollingRandomAccessFile&gt;\n    &lt;RollingRandomAccessFile\n      name=\"RollingApplicationFile\"\n      fileName=\"logs/app/application.log\"\n      filePattern=\"logs/app/$${date:yyyy-MM}/application-%d{MM-dd-yyyy}-%i.log.gz\"&gt;\n      &lt;PatternLayout pattern=\"${LOG_PATTERN}\"/&gt;\n      &lt;Policies&gt;\n        &lt;TimeBasedTriggeringPolicy/&gt;\n        &lt;SizeBasedTriggeringPolicy size=\"10 MB\"/&gt;\n      &lt;/Policies&gt;\n      &lt;DefaultRolloverStrategy max=\"20\"/&gt;\n    &lt;/RollingRandomAccessFile&gt;\n    &lt;RollingRandomAccessFile\n      name=\"RollingApplicationJsonFile\"\n      fileName=\"logs/json/app.json\"\n      filePattern=\"logs/json/$${date:yyyy-MM}/app-%d{MM-dd-yyyy}-%i.json.gz\"&gt;\n      &lt;JSONLayout eventEol=\"true\" properties=\"true\" stacktraceAsString=\"true\"\n        includeTimeMillis=\"true\"&gt;\n      &lt;/JSONLayout&gt;\n      &lt;Policies&gt;\n        &lt;TimeBasedTriggeringPolicy/&gt;\n        &lt;SizeBasedTriggeringPolicy size=\"10 MB\"/&gt;\n      &lt;/Policies&gt;\n      &lt;DefaultRolloverStrategy max=\"20\"/&gt;\n    &lt;/RollingRandomAccessFile&gt;\n    &lt;Console name=\"ConsoleAppender\" target=\"SYSTEM_OUT\" follow=\"true\"&gt;\n      &lt;PatternLayout pattern=\"${LOG_PATTERN}\"/&gt;\n    &lt;/Console&gt;\n  &lt;/Appenders&gt;\n  &lt;Loggers&gt;\n    &lt;Logger name=\"tt.logging\" level=\"debug\" additivity=\"false\"&gt;\n      &lt;AppenderRef ref=\"RollingCEFFile\"/&gt;\n    &lt;/Logger&gt;\n    &lt;Logger name=\"tt.observability\" level=\"info\" additivity=\"false\"&gt;\n      &lt;AppenderRef ref=\"RollingApplicationFile\"/&gt;\n      &lt;AppenderRef ref=\"RollingDevelopmentFile\"/&gt;\n      &lt;AppenderRef ref=\"ConsoleAppender\"/&gt;\n      &lt;AppenderRef ref=\"RollingApplicationJsonFile\"/&gt;\n    &lt;/Logger&gt;\n    &lt;Logger name=\"tt.observability\" level=\"trace\" additivity=\"false\"&gt;\n      &lt;AppenderRef ref=\"RollingDevelopmentFile\"/&gt;\n      &lt;AppenderRef ref=\"ConsoleAppender\"/&gt;\n      &lt;AppenderRef ref=\"RollingApplicationJsonFile\"/&gt;\n    &lt;/Logger&gt;\n    &lt;Root level=\"info\"&gt;\n      &lt;AppenderRef ref=\"ConsoleAppender\"/&gt;\n      &lt;AppenderRef ref=\"RollingApplicationJsonFile\"/&gt;\n    &lt;/Root&gt;\n  &lt;/Loggers&gt;\n&lt;/Configuration&gt;\n</code></pre>"},{"location":"logging/log4j2/#properties","title":"Properties","text":"<ol> <li>Logging pattern for application logs</li> </ol> <pre><code>%d{yyyy-MM-dd HH:mm:ss.SSS} %5p ${hostName} --- [%15.15t] %-40.40c{1.} %-4.4L : %X - %m%n%ex\n2023-08-17 17:22:48.763 DEBUG SWOPF2MNJFL --- [nio-8080-exec-2] t.o.s.j.JwtUtils 45 : {username=matze} - JWT Token is generated.\n</code></pre> <ol> <li>Logging pattern for CEF logs - output of the message from CEFlogService</li> </ol> <pre><code>%m%n\n</code></pre>"},{"location":"logging/log4j2/#appenders","title":"Appenders","text":"<p>RollingRandomAccessFile similar to the standard RollingFileAppender except it is always buffered. We saw a 20-200% performance improvement.</p> <p>Essentials:</p> <ul> <li>name: Name of the appender</li> <li>fileName: Name of the log file</li> <li>filePattern: Name of the log file pattern</li> <li>PatternLayout: Pattern of the log file</li> </ul> <p>Definition of four RollingRandomAccessFile:</p> <ul> <li> <p>RollingCEFFile: CEF logs</p> <ul> <li>CEF logs are used for SIEM integration</li> <li>(debug level an higher)</li> </ul> </li> <li> <p>RollingDevelopmentFile: Development logs</p> <ul> <li>Development logs are used for debugging</li> <li>(trace level and higher)</li> </ul> </li> <li> <p>RollingApplicationFile: Application logs</p> <ul> <li>Application logs are used for monitoring</li> <li>(info level and higher)</li> </ul> </li> <li> <p>RollingApplicationJsonFile: Application logs in JSON format</p> <ul> <li>Application logs are used to better analyze the logs within Grafana</li> <li>(trace level and higher)</li> </ul> </li> </ul> <p>And one default ConsoleAppender (trace level and higher).</p>"},{"location":"logging/log4j2/#loggers","title":"Loggers","text":"<p>Loggers are used to differentiate between different log levels and appenders.</p>"},{"location":"monitoring/grafana_alerting/","title":"Alerting","text":"<p>Alerts allow you to identify problems in your system moments after they occur. By quickly identifying unintended changes in your system, you can minimize disruptions to your services. (Grafana Labs, 2023)</p> <p>https://grafana.com/tutorials/grafana-fundamentals/?src=grafana_gettingstarted#create-a-grafana-managed-alert</p>"},{"location":"monitoring/grafana_alerting/#create-a-contact-point-for-grafana-managed-alerts","title":"Create a contact point for Grafana Managed Alerts","text":"<p>Email, Slack, PagerDuty, Webhook, VictorOps, OpsGenie, Discord, Microsoft Teams, Telegram, Google Chat, Google Hangouts Chat, Line, Pushover, Sensu, ServiceNow, Threema, Twilio, VictorOps, WeChat, and Zendesk.</p>"},{"location":"monitoring/grafana_alerting/#add-an-alert-rule-to-grafana","title":"Add an Alert Rule to Grafana","text":"<p>Use the Explore feature to create a query that returns a single value from Loki, Prometheus or Tempo.</p>"},{"location":"monitoring/grafana_dashboards/","title":"Import Dashboards in Grafana","text":""},{"location":"monitoring/grafana_dashboards/#scope","title":"Scope","text":"<p>One of the most important features of Grafana is the ability to create dashboards. Dashboards are a collection of panels that can be used to visualize data. Dashboards can be created from scratch or imported from the Grafana dashboard repository.</p> <p>One goal of the project is to provide some sample dashboards that are imported from startup. Here you can find the resource at GitHub.</p>"},{"location":"monitoring/grafana_dashboards/#implementation","title":"Implementation","text":""},{"location":"monitoring/grafana_dashboards/#blackbox-exporter","title":"Blackbox Exporter","text":"<p>The two dashboards for website monitoring are based on probing of endpoints over HTTP, HTTPS, DNS, IMCP and so on. The Blackbox exporter from Prometheus is used to allow probing and part of the docker-compose. It uses its own configuration file (./docker-setup/config/blackbox-exporter.yml) to define the modules (protocols). Example configuration:</p> <pre><code>modules:\n  http_2xx:\n    prober: http\n    timeout: 5s\n    http:\n      valid_http_versions: [\"HTTP/1.1\", \"HTTP/2.0\"]\n      valid_status_codes: []\n      method: GET\n      preferred_ip_protocol: \"ip4\"\n      ip_protocol_fallback: false \n</code></pre>"},{"location":"monitoring/grafana_dashboards/#prometheus-configuration","title":"Prometheus configuration","text":"<p>In addition, two Prometheus jobs are defined in the Prometheus configuration file ( ./docker-setup/config/prometheus.yml). These jobs are later used as datasource for dashboards. Example job configuration:</p> <pre><code>- job_name: http-monitoring         # To get metrics about the exporter\u2019s targets\n    metrics_path: /probe            # blackbox exporter opens a few probe_* endpoints\n    params:\n      module: [http_2xx]            # protocol to use for probing\n    static_configs:\n      - targets:\n          - obs:9464                # Target to probe sample backend application\n    relabel_configs:\n      - source_labels: [__address__]\n        target_label: __param_target\n      - source_labels: [__param_target]\n        target_label: instance\n      - target_label: __address__\n        replacement: host.docker.internal:9115  \n</code></pre>"},{"location":"monitoring/grafana_dashboards/#dashboards-and-grafana-volume-configuration","title":"Dashboards and Grafana volume configuration","text":"<p>The dashboards are stored as json files in the ./docker-setup/config/grafana/provisioning/dashboards folder. One point to note ist that the datasource (Prometheus job / query) has to be adapted to the Prometheus job name. In case of exporting a dashboard via Grafana all configurations are saved correctly.</p> <pre><code>{\n\"templating\": {\n    \"list\": [\n      {\n        \"hide\": 2,\n        \"label\": \"http_job\",\n        \"name\": \"http_job\",\n        \"query\": \"http-monitoring\", #Prometheus job name\n        \"queryValue\": \"\",\n        \"skipUrlSync\": false,\n        \"type\": \"constant\"\n      }\n    ]\n  }\n}\n</code></pre> <p>Within the dashboard.yml some meta information and scrape config is stored. These two components must be added as volumes to Grafana docker-compose configuration.</p> <pre><code>volumes:\n  - ./config/grafana/provisioning/dashboards:/var/lib/grafana/dashboard\n  - ./config/grafana/provisioning/dashboards/dashboard.yml:/etc/grafana/provisioning/dashboards/dashboard.yaml\n</code></pre>"},{"location":"monitoring/grafana_dashboards/#results","title":"Results","text":""},{"location":"monitoring/grafana_explore/","title":"Explore Loki, Prometheus and Tempo","text":"<p>Grafana\u2019s dashboard UI is all about building dashboards for visualization. Explore strips away the dashboard and panel options so that you can focus on the query. It helps you iterate until you have a working query and then think about building a dashboard. (Grafana Labs, 2023)</p>"},{"location":"monitoring/grafana_explore/#explore-loki","title":"Explore Loki","text":"<p>Analyze logs from all containers with aggregations, binary operation and formatter.</p> <p></p>"},{"location":"monitoring/grafana_explore/#explore-prometheus","title":"Explore Prometheus","text":"<p>Use PromQL to query Prometheus metrics.</p>"},{"location":"monitoring/grafana_explore/#cpu-usage-backend","title":"CPU usage backend","text":"<pre><code>system_cpu_usage{instance=\"obs:9464\"}\n</code></pre>"},{"location":"monitoring/grafana_explore/#sum-of-request-duration-grouped-by-uri","title":"Sum of request duration grouped by uri","text":"<pre><code>sum by(uri) (http_server_requests_seconds_sum{instance=\"obs:9464\"})\n</code></pre>"},{"location":"monitoring/grafana_explore/#sum-of-request-duration-grouped-by-uri-and-status-code","title":"Sum of request duration grouped by uri and status code","text":"<pre><code>sum by(status, uri) (http_server_requests_seconds_count{instance=\"obs:9464\"})\n</code></pre>"},{"location":"monitoring/grafana_explore/#explore-tempo","title":"Explore Tempo","text":"<p>Discover traces from Tempo and detect resource intensive operations.</p> <p></p>"}]}